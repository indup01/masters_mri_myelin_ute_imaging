{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d8c1f-3aea-4bce-a3f6-ae763c5a5c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "import torch\n",
    "import torchkbnufft as tkbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468ee4f5-c2bb-4359-bcc8-e5f51b9e9598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m t2_star_myelin \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3.0e-2\u001b[39m  \n\u001b[1;32m     16\u001b[0m t2_star_wm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7.0e-2\u001b[39m    \n\u001b[0;32m---> 17\u001b[0m inv_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mt1_wm\n\u001b[1;32m     18\u001b[0m echo_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4e-5\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#res in cm\n",
    "res = 0.1\n",
    "#fov in cm\n",
    "fov_x = 5\n",
    "fov_y = fov_x\n",
    "\n",
    "pixels_x = int(fov_x/res)\n",
    "pixels_y = int(fov_y/res)\n",
    "pixels = pixels_x*pixels_y\n",
    "print(pixels_x)\n",
    "t1_myelin = 4.0e-1 \n",
    "t1_wm = 8.5e-1      \n",
    "t2_myelin = 5.0e-2  \n",
    "t2_wm = 5.0e-2     \n",
    "t2_star_myelin = 3.0e-2  \n",
    "t2_star_wm = 7.0e-2    \n",
    "inv_time = np.log(2)*t1_wm\n",
    "echo_time = 4e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff38a11d-6df9-43bb-960e-7aa9eb9b0979",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.ones((pixels_x, pixels_y))\n",
    "\n",
    "mxy_myelin = (1-2*np.exp(-(inv_time/t1_myelin)))*np.exp(-(echo_time/t2_star_myelin))\n",
    "mxy_wm = (1-2*np.exp(-(inv_time/t1_wm)))*np.exp(-(echo_time/t2_star_wm))\n",
    "mxy_mixed = 0.5*((1-2*np.exp(-(inv_time/t1_wm)))*np.exp(-(echo_time/t2_star_wm))) + 0.5*((1-2*np.exp(-(inv_time/t1_myelin)))*np.exp(-(echo_time/t2_star_myelin)))\n",
    "\n",
    "print(mxy_myelin)\n",
    "print(mxy_wm)\n",
    "print(mxy_mixed)\n",
    "\n",
    "outer_square_size = int(1.0 * pixels_x) \n",
    "middle_square_size = int(0.6 * pixels_x)\n",
    "inner_square_size = int(0.25 * pixels_x)  \n",
    "\n",
    "# Calculate starting and ending indices for each square to center them\n",
    "outer_start = (pixels_x - outer_square_size) // 2\n",
    "outer_end = outer_start + outer_square_size\n",
    "\n",
    "middle_start = (pixels_x - middle_square_size) // 2\n",
    "middle_end = middle_start + middle_square_size\n",
    "\n",
    "inner_start = (pixels_x - inner_square_size) // 2\n",
    "inner_end = inner_start + inner_square_size\n",
    "\n",
    "# Define the intensity values for each section\n",
    "# Outermost square (100% WM - white, intensity = 1)\n",
    "image[outer_start:outer_end, outer_start:outer_end] = mxy_wm  # 100% WM\n",
    "\n",
    "# Middle square (50/50 of WM and myelin - medium gray)\n",
    "image[middle_start:middle_end, middle_start:middle_end] = mxy_mixed  # 50/50 of WM and myelin (gray)\n",
    "\n",
    "# Innermost square (100% myelin - black, intensity = 0)\n",
    "image[inner_start:inner_end, inner_start:inner_end] = mxy_myelin  # 100% myelin (black)\n",
    "\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(image, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c9cbd-3bf1-44ef-8468-92670c6af8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_image = np.fft.fft2(image)\n",
    "\n",
    "fft_image_shifted = np.fft.fftshift(f_image)  # Shift the zero-frequency component to the center\n",
    "\n",
    "# Compute the magnitude spectrum\n",
    "magnitude_spectrum = np.log(np.abs(fft_image_shifted) + 1)  # Log to enhance visibility\n",
    "\n",
    "# Plot the original image and its FFT magnitude spectrum\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"FFT Magnitude Spectrum - Log\")\n",
    "plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98a251-5be2-4670-b0a1-9dea89943a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterwarnings(\"ignore\") # ignore floor divide warnings\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58dfa7-9b4d-4c6d-a1c8-52db30273e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = image.shape\n",
    "grid_size = (tuple(int(dim * 2) for dim in im_size))\n",
    "print(im_size,grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d530f-1efc-4af3-95aa-d8a688e695b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the phantom to a tensor and unsqueeze coil and batch dimension\n",
    "image_t = torch.tensor(image).to(device).unsqueeze(0).unsqueeze(0)\n",
    "print('image shape: {}'.format(image_t.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff92ac8-fc4b-45e6-8337-f91d5c491ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res in mm and pixels\n",
    "res_mm = 1\n",
    "max_radii = 0.5/res_mm\n",
    "dis_points = 1/pixels_x\n",
    "print(max_radii)\n",
    "nspokes = int(2*np.pi*max_radii*pixels_x) # Number of rays\n",
    "num_samples_per_ray = int(max_radii*pixels_x) # Number of samples per ray\n",
    "print(nspokes,num_samples_per_ray)\n",
    "# Initialize an empty k-space list to store sampled points\n",
    "k_space = np.zeros((nspokes * num_samples_per_ray,), dtype=complex)\n",
    "\n",
    "# Create radial k-space sampling points (rays)\n",
    "angles = np.linspace(0, 2 * np.pi, nspokes, endpoint=False)  # Angle of the rays\n",
    "radii = np.linspace(0, max_radii, num_samples_per_ray)  # Radial distance (from the center)\n",
    "\n",
    "# Loop over rays to calculate Fourier coefficients\n",
    "kx_values = []\n",
    "ky_values = []\n",
    "for angle in angles:\n",
    "    for radius in radii:\n",
    "        # Calculate the kx, ky coordinates for each sampled point\n",
    "        kx = radius * np.cos(angle)  # x-component in frequency domain\n",
    "        ky = radius * np.sin(angle)  # y-component in frequency domain\n",
    "\n",
    "        # Store kx and ky for density compensation\n",
    "        kx_values.append(kx)\n",
    "        ky_values.append(ky)\n",
    "\n",
    "# Convert kx_values and ky_values to numpy arrays\n",
    "kx_values = np.array(kx_values)\n",
    "ky_values = np.array(ky_values)\n",
    "\n",
    "ktraj = np.stack((ky_values.flatten(), kx_values.flatten()), axis=0)\n",
    "print(ktraj.shape)\n",
    "\n",
    "# Find min and max values across all axes\n",
    "k_min = np.min(ktraj)\n",
    "k_max = np.max(ktraj)\n",
    "\n",
    "# Scale to [-pi, pi]\n",
    "ktraj_scaled = (ktraj - k_min) / (k_max - k_min) * (2 * np.pi) - np.pi\n",
    "ktraj = ktraj_scaled\n",
    "\n",
    "# Visualize the radial k-space sampling points (this shows the rays)\n",
    "plt.figure(figsize=(6, 6))\n",
    "for angle in angles:\n",
    "    x_vals = np.linspace(0, max_radii * np.cos(angle), num_samples_per_ray)\n",
    "    y_vals = np.linspace(0, max_radii * np.sin(angle), num_samples_per_ray)\n",
    "    plt.plot(x_vals, y_vals, 'b.', markersize=1)\n",
    "plt.title('Radial k-space Trajectory')\n",
    "plt.xlabel('kx')\n",
    "plt.ylabel('ky')\n",
    "plt.axis()\n",
    "plt.grid(True)\n",
    "\n",
    "# Adjust the axis limits to provide padding for text\n",
    "padding = 0.5 * max_radii  # 10% of max_radii for padding\n",
    "plt.xlim(-max_radii - padding, max_radii + padding)\n",
    "plt.ylim(-max_radii - padding, max_radii + padding)\n",
    "\n",
    "# Plot markers on the axes at kmax and -kmax\n",
    "plt.plot([max_radii, -max_radii], [0, 0], 'ro', label='kx markers')  # Markers along x-axis\n",
    "plt.plot([0, 0], [max_radii, -max_radii], 'ro', label='ky markers')  # Markers along y-axis\n",
    "\n",
    "# Add text labels near the markers with offsets\n",
    "text_offset = 0.05 * max_radii  # Offset for the text relative to the marker\n",
    "plt.text(max_radii + text_offset, 0, 'k x,max', color='red', fontsize=10, ha='left', va='center')  # x-axis positive\n",
    "plt.text(-max_radii - text_offset, 0, '-k x,max', color='red', fontsize=10, ha='right', va='center')  # x-axis negative\n",
    "plt.text(0, max_radii + text_offset, 'k y,max', color='red', fontsize=10, ha='center', va='bottom')  # y-axis positive\n",
    "plt.text(0, -max_radii - text_offset, '-k y,max', color='red', fontsize=10, ha='center', va='top')  # y-axis negative\n",
    "\n",
    "plt.show()\n",
    "#print(ktraj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc92c5-f802-4435-9d23-28c5acf6adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert k-space trajectory to a tensor\n",
    "ktraj = torch.tensor(ktraj).to(device)\n",
    "print('ktraj shape: {}'.format(ktraj.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be43fe-f445-4847-ae59-3fff57d86c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im_size,grid_size)\n",
    "\n",
    "# create NUFFT objects, use 'ortho' for orthogonal FFTs\n",
    "nufft_ob = tkbn.KbNufft(\n",
    "    im_size=im_size,\n",
    "    grid_size=grid_size,\n",
    ").to(image_t)\n",
    "adjnufft_ob = tkbn.KbNufftAdjoint(\n",
    "    im_size=im_size,\n",
    "    grid_size=grid_size,\n",
    ").to(image_t)\n",
    "\n",
    "print(nufft_ob)\n",
    "print(adjnufft_ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8da6b6-b1c9-4d65-a97a-d6bcdfb20ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the kernel\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs.flat[0].plot(np.real(nufft_ob.table_0.cpu().numpy()))\n",
    "axs.flat[1].plot(np.imag(nufft_ob.table_0.cpu().numpy()))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61779b81-7b79-4ec5-ad0e-3d846b0b1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(image_t.shape)\n",
    "\n",
    "# Convert image_t to complex if it's real (with last dimension not equal to 2)\n",
    "if image_t.ndimension() == 3 and image_t.shape[-1] != 2:  # Real input\n",
    "    print(\"Converting real image to complex...\")\n",
    "    image_t = torch.stack([image_t, torch.zeros_like(image_t)], dim=-1)  # Convert to complex\n",
    "\n",
    "#print(image_t.shape)\n",
    "\n",
    "# Check the dtype of image_t\n",
    "#print(image_t.dtype)\n",
    "\n",
    "# If it's real, convert it to complex\n",
    "if image_t.dtype != torch.complex128:\n",
    "    print(\"Converting image to complex dtype...\")\n",
    "    image_t = image_t.to(torch.complex128)  # Convert to complex type\n",
    "\n",
    "# Now pass the image to the nufft_ob function\n",
    "kdata = nufft_ob(image_t, ktraj)\n",
    "\n",
    "# add some noise (robustness test)\n",
    "#siglevel = torch.abs(kdata).mean()\n",
    "#kdata = kdata + (siglevel/5) * torch.randn(kdata.shape).to(kdata)\n",
    "print(kdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c716a8-fa38-432e-9ae1-1b3b9dbd07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the k-space data on log-scale\n",
    "kdata_numpy = np.reshape(kdata.cpu().numpy(), (nspokes,num_samples_per_ray))\n",
    "plt.imshow(np.log10(np.absolute(kdata_numpy)))\n",
    "plt.gray()\n",
    "plt.title('k-space data, log10 scale')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515c871-5649-4a92-b0e4-f04784cc93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ktraj.shape)\n",
    "# adjnufft back\n",
    "# method 1: no density compensation (blurry image)\n",
    "image_blurry = adjnufft_ob(kdata, ktraj)\n",
    "\n",
    "# method 2: use density compensation\n",
    "dcomp = tkbn.calc_density_compensation_function(ktraj=ktraj, im_size=im_size)\n",
    "image_sharp = adjnufft_ob(kdata * dcomp, ktraj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2c0c0e-f2c6-4f8a-9275-4af98b271b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the images\n",
    "image_blurry_numpy = np.squeeze(image_blurry.cpu().numpy())\n",
    "\n",
    "image_sharp_numpy = np.squeeze(image_sharp.cpu().numpy())\n",
    "\n",
    "print(image_sharp_numpy.shape)\n",
    "print(image.shape)\n",
    "\n",
    "diff_image = np.abs(image_sharp - image)\n",
    "diff_image = np.squeeze(diff_image)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(np.absolute(image_blurry_numpy))\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.title('blurry image')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(np.absolute(image_sharp_numpy))\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.title('sharp image (with Pipe dcomp)')\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(np.absolute(image))\n",
    "plt.gray()\n",
    "plt.colorbar()\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(diff_image, cmap='hot')\n",
    "plt.colorbar()\n",
    "plt.title('Difference Image')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd3668-4f83-4f32-9dc7-226752ce0f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5f3d1-5437-4e96-911d-da5ab8858ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def2876-1bbf-4bee-9f5f-363de950b142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_kernel",
   "language": "python",
   "name": "fyp_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
